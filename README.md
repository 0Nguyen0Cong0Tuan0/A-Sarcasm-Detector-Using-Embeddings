# Building a Sarcasm detector using Embeddings

Traditional text processing techniques often fail to capture the deeper meaning of words. While no absolute numeric encoding can fully encapsulate meaning, relative representations can be learned. 

**Embeddings** provide a way to **represent words as high-dimensional vectors**, where their **directions reflect contextual relationships**. By analyzing these vectors, we can **determine the overall sentiment of a sentence based on its word composition**.

This project focuses on leveraging **embeddings** to **build a sarcasm detector** using the **Sarcasm dataset**. By training a model on these representations, we aim to **improve its ability to distinguish sarcastic statements from literal ones**. Additionally, visualization tools will help illustrate how words are mapped to vectors and how they contribute to classification.